{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessment needs mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex\n",
    "from zipfile import ZipFile\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import re\n",
    "import calendar\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import contextily as ctx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## >> Input required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define local authority name and filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_authority_name = '...' # Local authority name to facilitate mapping\n",
    "log_input_file = '.../log.csv' # Filepath to log\n",
    "postcode_input_file = '.../assessment_postcode_data.xlsx' #Filepath to file containing postcodes relating to assessments\n",
    "output_folder = '...' # Filepath to folder where the analysis and charts will be saved\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "risk_factor_output_folder = os.path.join(output_folder, 'Specific Risk Factors')\n",
    "if not os.path.exists(risk_factor_output_folder):\n",
    "    os.makedirs(risk_factor_output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1 Define Useful References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define risk codes and their signification\n",
    "risk_codes = ['1A', '1B', '1C', '2A', '2B', '2C', '3A', '3B', '3C', '4A', '4B', '4C', '5A', '5B', '5C', '6A', '6B', '6C', '7A', \n",
    "              '8A','8B', '8C', '8D', '8E', '8F', '9A', '10A', '11A', '12A', '13A', '14A', '15A', '16A', '17A', '18A', '19A', \n",
    "              '20', '21', '22A', '23A']\n",
    "\n",
    "risk_map = {\n",
    "    '1A':'Alcohol misuse - child', \n",
    "    '1B':'Alcohol misuse - parents/carer', \n",
    "    '1C':'Alcohol misuse - other', \n",
    "    '2A':'Drug misuse - child', \n",
    "    '2B':'Drug misuse - parent/carer', \n",
    "    '2C':'Drug misuse - other', \n",
    "    '3A':'Domestic violence - child', \n",
    "    '3B':'Domestic violence - parent/carer', \n",
    "    '3C':'Domestic violence - other', \n",
    "    '4A':'Mental health - child', \n",
    "    '4B':'Mental health - parent/carer', \n",
    "    '4C':'Mental health - other', \n",
    "    '5A':'Learning disability - child', \n",
    "    '5B':'Learning disability - parent/carer', \n",
    "    '5C':'Learning disability - other', \n",
    "    '6A':'Physical disability/illness - child', \n",
    "    '6B':'Physical disability/illness - parent/carer', \n",
    "    '6C':'Physical disability/illness - other', \n",
    "    '7A':'Young carer', \n",
    "    '8A':'Privately fostered (not used anymore)',\n",
    "    '8B':'Privately fostered - overseas children who intend to return', \n",
    "    '8C':'Privately fostered - overseas children who intend to stay', \n",
    "    '8D':'Privately fostered - UK children in educational placements', \n",
    "    '8E':'Privately fostered - UK children making alternative family arrangements', \n",
    "    '8F':'Privately fostered - other', \n",
    "    '9A':'Unaccompanied Asylum Seeking Child', \n",
    "    '10A':'Missing', \n",
    "    '11A':'Child sexual exploitation', \n",
    "    '12A':'Trafficking', \n",
    "    '13A':'Gangs', \n",
    "    '14A':'Socially unacceptable behaviour', \n",
    "    '15A':'Self-harm', \n",
    "    '16A':'Neglect', \n",
    "    '17A':'Emotional abuse', \n",
    "    '18A':'Physical abuse', \n",
    "    '19A':'Sexual abuse', \n",
    "    '20':'Other', \n",
    "    '21':'No factors identified', \n",
    "    '22A':'Female genital mutilation', \n",
    "    '23A':'Abuse linked to faith or belief'\n",
    "}\n",
    "\n",
    "code_map = {\n",
    "    '1':'Alcohol Abuse', \n",
    "    '2':'Drug Abuse', \n",
    "    '3':'Domestic Violence', \n",
    "    '4':'Mental Health', \n",
    "    '5':'Learning Disability', \n",
    "    '6':'Physical Disability', \n",
    "    '7A':'Young Carer', \n",
    "    '8':'Privately fostered', \n",
    "    '9A':'UASC', \n",
    "    '10A':'Missing', \n",
    "    '11A':'Sexual exploitation', \n",
    "    '12A':'Trafficking', \n",
    "    '13A':'Gangs', \n",
    "    '14A':'Behaviour', \n",
    "    '15A':'Self-harm', \n",
    "    '16A':'Neglect', \n",
    "    '17A':'Emotional abuse', \n",
    "    '18A':'Physical abuse', \n",
    "    '19A':'Sexual abuse', \n",
    "    '20':'Other', \n",
    "    '21':'No factors id.', \n",
    "    '22A':'FGM', \n",
    "    '23A':'Abuse Linked to Faith/belief'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2 Read in geography related data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all of the geography files (these can be found in the readme) and specify the path to their location\n",
    "\n",
    "# filepath to postcode geographic information\n",
    "postcode_geography_file = '.../ukpostcodes.zip' #Postcode file location\n",
    "lsoa_shapes_file = '.../geo-lsoa.zip' #LSOA shapes file location\n",
    "lau_shapes_file = './supporting_data/geo-lau.geojson.bz2' #LAU shapes file location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in postcode_geography_file to postcode_lat_lon\n",
    "with ZipFile(postcode_geography_file) as myzip:\n",
    "    with myzip.open('ukpostcodes.csv') as myfile:\n",
    "        postcode_lat_lon = pd.read_csv(myfile)\n",
    "\n",
    "postcode_lat_lon = postcode_lat_lon[['postcode','latitude','longitude']] \n",
    "postcode_lat_lon.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in lsoa_shapes_file to lsoas\n",
    "lsoas = gpd.read_file(lsoa_shapes_file)\n",
    "lsoas = lsoas[[\"lsoa11cd\", \"lsoa11nm\", \"geometry\"]]\n",
    "lsoas.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in lau_shapes_file (local authority) to laus\n",
    "laus = gpd.read_file(lau_shapes_file)\n",
    "laus = laus[[\"lau118cd\",\"lau118nm\",\"geometry\"]]\n",
    "laus.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Define Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1 Define General Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Def start_end_date function giving start date and end date for the analysis\n",
    "\n",
    "def start_end_date(date, period):\n",
    "    '''\n",
    "    Returns start and end date based on a given date and given period (months)\n",
    "    The given date must be a Timestamp\n",
    "    The end date will be the last day of the month prior to the given date\n",
    "    The start date will be the first day of the month after doing (end date - period)\n",
    "    '''\n",
    "    # If given date is already at the end of the month\n",
    "    if date.day == calendar.monthrange(date.year, date.month)[1]:\n",
    "        end_date = date\n",
    "        start_date = end_date + relativedelta(months=-(period-1))\n",
    "        start_date = start_date.replace(day=1)\n",
    "    # If given date is not at the end of the month\n",
    "    else:\n",
    "        end_date_intermediate = date.replace(day=1)\n",
    "        end_date = end_date_intermediate - np.timedelta64(1, 'D')\n",
    "        start_date = end_date_intermediate + relativedelta(months=-period)\n",
    "    try:\n",
    "        start_date = start_date.replace(hour = 0, minute = 0, second = 0)\n",
    "    except:\n",
    "        print('No time in start date')\n",
    "    try:\n",
    "        end_date = end_date.replace(hour = 23, minute = 59, second = 59)\n",
    "    except:\n",
    "        print('No time in end date')\n",
    "    # Turn into pd-compatible format\n",
    "    start_date = pd.to_datetime(start_date)\n",
    "    end_date = pd.to_datetime(end_date)\n",
    "    return start_date, end_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1 Create base dataframe: risk_factors_and_postcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load log input file\n",
    "log = pd.read_csv(log_input_file)\n",
    "# Convert date column to datetime\n",
    "log['Date'] = pd.to_datetime(log['Date'])\n",
    "\n",
    "# Load local authority postcode file\n",
    "postcodes = pd.read_excel(postcode_input_file)\n",
    "# Ensure column names are correct for future matching\n",
    "postcodes.columns = ['CUID', 'Date','Postcode']\n",
    "# Convert date column to datetime\n",
    "postcodes['Date'] = pd.to_datetime(postcodes['Date'])\n",
    "\n",
    "# Filter log to contain only CIN Census Assessment Close datapoints\n",
    "log_assessment_close = log[log.Type == 'AssessmentAuthorisationDate']\n",
    "# Define columns that we want to keep in the new dataframe\n",
    "relevant_columns = ['CUID', 'Date','Type']\n",
    "# Create risk factor log, by splitting the Factors column and counting the values into new columns\n",
    "risk_factor_log = pd.concat([log_assessment_close[relevant_columns],log_assessment_close['Factors'].str.split(',', expand = True).stack().str.get_dummies().sum(level=0)],1)\n",
    "\n",
    "# Merge risk factors with postcodes\n",
    "risk_factors_and_postcodes = risk_factor_log.merge(postcodes, how = 'left', on =['CUID','Date'])\n",
    "risk_factors_and_postcodes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2 Add area data to base dataframe: risk_factors_with_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all entries without postcodes\n",
    "risk_factors_with_areas = risk_factors_and_postcodes[~risk_factors_and_postcodes.Postcode.isnull()]\n",
    "# Merge postcode_lat_lon onto risk_factors_with_areas to add the latitude and longitude data\n",
    "risk_factors_with_areas = risk_factors_with_areas.merge(postcode_lat_lon, on = 'Postcode', how = 'left')\n",
    "# Drop any rows where 'Latitude' or 'Longitude' are not populated (some newer postcodes are not in postcodes_lat_lon database)\n",
    "risk_factors_with_areas = risk_factors_with_areas.dropna(subset=[\"Latitude\", \"Longitude\"])\n",
    "# Rename columns to facilitate creation of coordinates\n",
    "risk_factors_with_areas = risk_factors_with_areas.rename(columns = {'Longitude':'longitude','Latitude':'latitude'})\n",
    "\n",
    "# Create a series of coordinates of coordinates, by applying 'Point' to latitude and longitude columns \n",
    "coords = pd.Series(list(zip(risk_factors_with_areas.longitude,risk_factors_with_areas.latitude))).apply(Point)\n",
    "crs = {'init' :'epsg:4326'} # Set geometry to match our maps\n",
    "# Turn coordinates into a GeoDataFrame, which will be used to determine the LAUs and LSOAs the postcodes sit within\n",
    "coords = gpd.GeoDataFrame(pd.DataFrame(coords, \n",
    "            columns=[\"coordinates\"]),crs = crs, geometry=\"coordinates\")\n",
    "\n",
    "# Add new lsoa columns to risk_factors_with_areas by joining lsoas dataframe to new coordinates DataFrame\n",
    "risk_factors_with_areas[[\"lsoa11cd\",\"lsoa11nm\"]] = gpd.sjoin(coords, lsoas, how=\"left\", \n",
    "                                                             op=\"intersects\")[[\"lsoa11cd\",\"lsoa11nm\"]]\n",
    "\n",
    "# Add new lau columns to risk_factors_with_areas by joining laus dataframe to new coordinates DataFrame\n",
    "risk_factors_with_areas[[\"lau118cd\",\"lau118nm\"]] = gpd.sjoin(coords, laus, how=\"left\", op=\"intersects\")[[\"lau118cd\",\"lau118nm\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3 Regroup risk factors to create more general categories and drop entries from outside LA: risk_factors_with_areas_regrouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define regroup function for regrouping similar factors to create more general categories\n",
    "def regroup(df, factors_to_group):\n",
    "    columns = df.columns.tolist()\n",
    "    for factor in factors_to_group:\n",
    "        regex = r\",({}[A-Z])\".format(factor)\n",
    "        group = re.findall(regex, ','.join(columns))\n",
    "        df[factor] = df[group].sum(axis=1)\n",
    "        df.drop(labels=group, axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "risk_factors_with_areas_regrouped = risk_factors_with_areas.copy()\n",
    "\n",
    "# Define factors that should be regrouped\n",
    "factors_for_regrouping = ['1', '2', '3', '4', '5', '6', '8']\n",
    "risk_factors_with_areas_regrouped = regroup(risk_factors_with_areas_regrouped, factors_for_regrouping)\n",
    "\n",
    "# Set the index on Date\n",
    "risk_factors_with_areas_regrouped = risk_factors_with_areas_regrouped.set_index('Date')\n",
    "\n",
    "# Drop entries from outside the local authority to facilitate mapping\n",
    "risk_factors_with_areas_regrouped = risk_factors_with_areas_regrouped[risk_factors_with_areas_regrouped.lau118nm == local_authority_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.4 Create DataFrame of overall volume counts by Risk Factor: risk_factors_current_previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to create an annual count of risk factors across a local authority\n",
    "# Note: column_id needs to be specified to be able to differentiate the different DataFrames in the next step\n",
    "def calculate_annual_risk_factor_volumes(df, year_end_date, column_id):\n",
    "    start_date, end_date = start_end_date(year_end_date, 12)\n",
    "    filtered_df = df[(df.index >= start_date)&(df.index <= end_date)]\n",
    "    annual_count_of_risk_factors = pd.DataFrame(filtered_df[list_of_risk_columns].sum(), columns = [column_id])\n",
    "    return filtered_df, annual_count_of_risk_factors\n",
    "\n",
    "# Create list of risk columns for formatting\n",
    "list_of_risk_columns = ['1', '2', '3', '4', '5', '6','7A', '8', '9A','10A', '11A', '12A', '13A', '14A', '15A', '16A',\n",
    "       '17A', '18A', '19A', '20', '21', '22A', '23A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame of current and previous year risk factors, with comparison\n",
    "\n",
    "# Define current year end date\n",
    "latest_year_end_date = risk_factors_with_areas_regrouped.index.max()\n",
    "# Define previous year end date\n",
    "prev_year_end_date = risk_factors_with_areas_regrouped.index.max() - relativedelta(years=1)\n",
    "\n",
    "# Create current year count of risk factors\n",
    "risk_factors_current, la_risk_count_current = calculate_annual_risk_factor_volumes(risk_factors_with_areas_regrouped, latest_year_end_date, 'Current Year')\n",
    "# Create previous year count of risk factors\n",
    "risk_factors_prev, la_risk_count_prev = calculate_annual_risk_factor_volumes(risk_factors_with_areas_regrouped, prev_year_end_date, 'Previous Year')\n",
    "\n",
    "# Merge the current and previous year DataFrames to create comparison DataFrame\n",
    "risk_factors_current_previous = la_risk_count_current.merge(la_risk_count_prev, how = 'left',left_index=True, right_index = True)\n",
    "\n",
    "# Caclulate a column showing change from previous year\n",
    "risk_factors_current_previous['% Change from Previous Year'] = (risk_factors_current_previous['Current Year']-risk_factors_current_previous['Previous Year'])/(risk_factors_current_previous['Previous Year'])\n",
    "\n",
    "# Map the risk factor codes to their names for easier understanding\n",
    "risk_factors_current_previous['Risk Factor'] = risk_factors_current_previous.index.map(code_map)\n",
    "risk_factors_current_previous.to_excel(os.path.join(output_folder,'risk_factors_current_previous.xlsx'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.5 Identify risk factors to map (either by highest volume or highest change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate top 5 risk factors by volume\n",
    "top_5_risk_factors_volume = list(risk_factors_current_previous.nlargest(5, columns = 'Current Year').index)\n",
    "# Filter dataframe to find top 5 risk factors to look at\n",
    "top_5_risk_factors_growth = list(risk_factors_current_previous.nlargest(5, columns = '% Change from Previous Year').index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Mapping Overall Assessments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.1. Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the create total assessments df function, including volumes and changes in assessment by lsoa, and the lsoa geometry\n",
    "def create_total_assessments_df(df_current,df_previous):\n",
    "    # Group current year data by lsoa\n",
    "    current_year = pd.DataFrame(df_current.groupby('lsoa11nm')['CUID'].count())\n",
    "    # Group previous year data by lsoa\n",
    "    previous_year = pd.DataFrame(df_previous.groupby('lsoa11nm')['CUID'].count())\n",
    "    # Merge the two together\n",
    "    current_and_prev_year = current_year.merge(previous_year, how='left', left_index=True, right_index = True).reset_index()\n",
    "    current_and_prev_year.columns = ['lsoa11nm', 'Total Current Year', 'Total Previous Year']\n",
    "    # Calculate change from previous year (in absolute values, rather than % change)\n",
    "    current_and_prev_year['Change from Previous Year'] = current_and_prev_year['Total Current Year'] - current_and_prev_year['Total Previous Year']\n",
    "    # Add Geometry\n",
    "    total_assessments_df = lsoas.merge(current_and_prev_year, how='right', on = 'lsoa11nm')\n",
    "    # Save file in case of desire to review\n",
    "    total_assessments_df.to_excel(os.path.join(output_folder, 'Assessment Prevalence and Change by LSOA.xlsx'))\n",
    "    return total_assessments_df\n",
    "\n",
    "# Define create_assessment_prevalence function, which plots the volume of assessments by lsoa, and saves to output folder\n",
    "def create_assessment_prevalence(df, authority):\n",
    "    # Filter for only the shape of the relevant local authority\n",
    "    la_shape = laus[laus['lau118nm']==authority]\n",
    "    # Ensure coordinate systems are the same\n",
    "    df = df.to_crs(epsg=3857)\n",
    "    la_shape = la_shape.to_crs(epsg=3857)\n",
    "    # Specify map parameters\n",
    "    fig, ax = plt.subplots(1, figsize=(9,9))\n",
    "    plt.tight_layout()\n",
    "    plt.title(\"{} - Total Assessments\".format(authority), size = 15)\n",
    "    plt.axis('off')\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "    plot_cfg = {\"vmin\": 0, # This is 0, as there will be no 'negative' entries\n",
    "                \"linewidth\": 0.05, \n",
    "                \"cmap\": 'OrRd',\n",
    "                \"legend\": True,\n",
    "                \"alpha\": .8}\n",
    "    la_shape.plot(ax=ax, \n",
    "                  color='none', \n",
    "                  edgecolor='black', \n",
    "                  linewidth=5)\n",
    "    df.plot(ax=ax, column='Total Current Year', **plot_cfg, \n",
    "                  legend_kwds={'label':'Volume of Assessments'}, cax=cax)\n",
    "    # Add map beneath graph\n",
    "    try:\n",
    "        ctx.add_basemap(ax)\n",
    "    except:\n",
    "        print(\"Fetching map resulted in error for {}\".format(authority))\n",
    "        pass\n",
    "    # Save figure to output folders\n",
    "    plt.savefig(os.path.join(output_folder, '{} - Total Assessments.png'.format(authority)),bbox_inches = \"tight\")\n",
    "    \n",
    "# Create Map of Prevalence\n",
    "def create_change_in_assessment_prevalence(df, authority):\n",
    "    # Filter for only the shape of the relevant local authority\n",
    "    la_shape = laus[laus['lau118nm']==authority]\n",
    "    # Ensure coordinate systems are the same\n",
    "    df = df.to_crs(epsg=3857)\n",
    "    la_shape = la_shape.to_crs(epsg=3857)\n",
    "    # Specify maximum change value to ensure legend is equal on both sides (feeds into vmin and vmax parameters)\n",
    "    maximum_change_value = max(df['Change from Previous Year'].max(), -df['Change from Previous Year'].min())\n",
    "    # Specify graph parameters\n",
    "    fig, ax = plt.subplots(1, figsize=(9,9))\n",
    "    plt.tight_layout()\n",
    "    plt.title(\"{} - Change in Assessments\".format(authority),size = 15)\n",
    "    plt.axis('off')\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "    plot_cfg = {\n",
    "                \"vmin\": -maximum_change_value,\n",
    "                \"vmax\": maximum_change_value,\n",
    "                \"linewidth\": 0.05, \n",
    "                \"cmap\": 'RdYlGn_r',\n",
    "                \"legend\": True,\n",
    "                \"alpha\": .8}\n",
    "    la_shape.plot(ax=ax, color='none', edgecolor='black', linewidth=5)\n",
    "    df.plot(ax=ax, column='Change from Previous Year', **plot_cfg,\n",
    "            legend_kwds={'label':'Change in Volume of Assessments'}, cax = cax)\n",
    "    # Add map beneath graph\n",
    "    try:\n",
    "        ctx.add_basemap(ax)\n",
    "    except:\n",
    "        print(\"Fetching map resulted in error for {}\".format(authority))\n",
    "        pass\n",
    "    # Save figure to output folder\n",
    "    plt.savefig(os.path.join(output_folder, '{} - Change in Assessments.png'.format(authority)),bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.2 Create Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create total assessments DataFrame using risk_factors_current and risk_factors_prev from section 3.4\n",
    "total_assessments_df = create_total_assessments_df(risk_factors_current, risk_factors_prev)\n",
    "\n",
    "# Create assessment prevalence and change in assessment prevalence graphs, based on total_assessments_df\n",
    "create_assessment_prevalence(total_assessments_df, local_authority_name)\n",
    "create_change_in_assessment_prevalence(total_assessments_df, local_authority_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Mapping Specific Risk Factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2.1. Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to create DataFrame driving risk factor specific maps, showing volume, change and geometry\n",
    "def create_risk_factor_lsoa_df(risk_factor):\n",
    "    # Group current and prev year data by lsoa for a specified risk factor\n",
    "    current_year = pd.DataFrame(risk_factors_current.groupby('lsoa11nm')[risk_factor].sum())\n",
    "    previous_year = pd.DataFrame(risk_factors_prev.groupby('lsoa11nm')[risk_factor].sum())\n",
    "    # Merge the two together\n",
    "    current_and_prev_year = current_year.merge(previous_year, how='left', left_index=True, right_index = True).reset_index()\n",
    "    current_and_prev_year.columns = ['lsoa11nm', 'Total Current Year', 'Total Previous Year']\n",
    "    # Caclulate change from previous year\n",
    "    current_and_prev_year['Change from Previous Year'] = current_and_prev_year['Total Current Year'] - current_and_prev_year['Total Previous Year']\n",
    "    # Add Geometry\n",
    "    lsoa_risk_factors_and_geometry = lsoas.merge(current_and_prev_year, how='right', on = 'lsoa11nm')\n",
    "    return lsoa_risk_factors_and_geometry\n",
    "\n",
    "# Define function to create prevalence graphs by risk factors\n",
    "def create_prevalence_graphs(risk_factor, local_authority):\n",
    "    # Define LA Shape\n",
    "    la_shape = laus[laus['lau118nm']==local_authority]\n",
    "    # Create DataFrame for specified risk factor\n",
    "    df = create_risk_factor_lsoa_df(risk_factor)\n",
    "    # Access risk factor name for titles\n",
    "    risk_factor_name = code_map[risk_factor]\n",
    "    # Save file in case of desire to review\n",
    "    df.to_excel(os.path.join(risk_factor_output_folder, '{} Risk Factor Prevalence and Change by LSOA.xlsx'.format(risk_factor_name)))\n",
    "    # Ensure coordinate systems are the same\n",
    "    df = df.to_crs(epsg=3857)\n",
    "    la_shape = la_shape.to_crs(epsg=3857)\n",
    "    # Specify graph parameters\n",
    "    fig, ax = plt.subplots(1, figsize=(9,9))\n",
    "    plt.tight_layout()\n",
    "    plt.title(\"{} - Assessments Showing Risk Factor {} \".format(local_authority, risk_factor_name), size = 15)\n",
    "    plt.axis('off')\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "    plot_cfg = {\n",
    "                \"vmin\": 0,\n",
    "                \"linewidth\": 0.05, \n",
    "                \"cmap\": 'OrRd',\n",
    "                \"legend\": True,\n",
    "                \"alpha\": .8}\n",
    "    la_shape.plot(ax=ax, color='none', edgecolor='black', linewidth=5)\n",
    "    df.plot(ax=ax, column='Total Current Year', **plot_cfg,legend_kwds={'label':'Volume of Assessments with Need Identified'}, cax = cax)\n",
    "    # Add map underneath\n",
    "    try:\n",
    "        ctx.add_basemap(ax)\n",
    "    except:\n",
    "        print(\"Fetching map resulted in error for {}\".format(local_authority))\n",
    "        pass\n",
    "    # Save figure to output folder\n",
    "    plt.savefig(os.path.join(risk_factor_output_folder, '{} - Prevalence of Risk Factor {}.png'.format(local_authority, risk_factor_name)),bbox_inches = \"tight\")\n",
    "    \n",
    "def create_change_graphs(risk_factor, local_authority):\n",
    "    # Define LA Shape\n",
    "    la_shape = laus[laus['lau118nm']==local_authority]\n",
    "    # Create DataFrame for specified risk factor\n",
    "    df = create_risk_factor_lsoa_df(risk_factor)\n",
    "    # Access risk factor name for titles\n",
    "    risk_factor_name = code_map[risk_factor]\n",
    "    # Remove any values where 'Change from Previous Year' is null, they will break the graph otherwise\n",
    "    df = df[df['Change from Previous Year'].isnull() == False]\n",
    "    # Calculate maximum change value to input into legend\n",
    "    maximum_change_value = max(df['Change from Previous Year'].max(), -df['Change from Previous Year'].min())\n",
    "    # Ensure coordinate systems are the same\n",
    "    df = df.to_crs(epsg=3857)\n",
    "    la_shape = la_shape.to_crs(epsg=3857)\n",
    "    # Specify graph paramaters\n",
    "    fig, ax = plt.subplots(1, figsize=(9,9))\n",
    "    plt.title(\"{} - Change from Previous Year Risk Factor {} \".format(local_authority, risk_factor_name), size =15)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "    plot_cfg = {\n",
    "                \"vmin\": -maximum_change_value,\n",
    "                \"vmax\": maximum_change_value,\n",
    "                \"linewidth\": 0.05, \n",
    "                \"cmap\": 'RdYlGn_r',\n",
    "                \"legend\": True,\n",
    "                \"alpha\": .8}\n",
    "    la_shape.plot(ax=ax, color='none', edgecolor='black', linewidth=5)\n",
    "    df.plot(ax=ax, column='Change from Previous Year', **plot_cfg,legend_kwds={'label':'Change in Volume of Assessments with Need Identified'}, cax = cax)\n",
    "    # Add underlying map\n",
    "    try:\n",
    "        ctx.add_basemap(ax)\n",
    "    except:\n",
    "        print(\"Fetching map resulted in error for {}\".format(local_authority))\n",
    "        pass\n",
    "    # Save figure to risk factors output folder\n",
    "    plt.savefig(os.path.join(risk_factor_output_folder, '{} - Change in Risk Factor {}.png'.format(local_authority, risk_factor_name)),bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create risk factors specific maps for top 5 risk factors by volume\n",
    "for risk_factors in top_5_risk_factors_volume:\n",
    "    create_prevalence_graphs(risk_factors, local_authority_name)\n",
    "    create_change_graphs(risk_factors, local_authority_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
